name: 'Claude Code Watchdog'
description: 'Your AI watchdog that watches for test failures and heals them automatically'
author: 'CardScan.ai'

inputs:
  anthropic_api_key:
    description: 'Anthropic API key for Claude'
    required: true
  severity_threshold:
    description: 'Minimum severity to process (ignore|low|medium|high|critical)'
    required: false
    default: 'medium'
  create_issues:
    description: 'Create GitHub issues for failures'
    required: false
    default: 'true'
  create_fixes:
    description: 'Attempt to implement fixes automatically'
    required: false
    default: 'true'
  rerun_tests:
    description: 'Attempt to re-run failed tests to confirm fixes'
    required: false
    default: 'false'
  debug_mode:
    description: 'Upload watchdog artifacts for debugging'
    required: false
    default: 'false'

outputs:
  severity:
    description: 'Failure severity (ignore|low|medium|high|critical)'
    value: ${{ steps.ensure-outputs.outputs.severity }}
  action_taken:
    description: 'What action was taken (issue_created|issue_updated|pr_created|pr_updated|tests_fixed|none)'
    value: ${{ steps.ensure-outputs.outputs.action_taken }}
  issue_number:
    description: 'GitHub issue number if created or updated'
    value: ${{ steps.ensure-outputs.outputs.issue_number }}
  pr_number:
    description: 'PR number if fixes were created'
    value: ${{ steps.ensure-outputs.outputs.pr_number }}
  tests_passing:
    description: 'true if re-run tests passed after fixes'
    value: ${{ steps.ensure-outputs.outputs.tests_passing }}

runs:
  using: 'composite'
  steps:
    - name: üêï Artemis is on the case
      shell: bash
      run: |
        echo "üêï Woof! Artemis the Watchdog detected test failures..."
        echo "üîç Starting intelligent failure analysis..."

    - name: Validation checks
      shell: bash
      run: |
        chmod +x ${{ github.action_path }}/scripts/validate.sh
        ${{ github.action_path }}/scripts/validate.sh
      continue-on-error: false  # Only fail on missing API key
      env:
        GH_TOKEN: ${{ github.token }}
        ANTHROPIC_API_KEY: ${{ inputs.anthropic_api_key }}
        CREATE_FIXES: ${{ inputs.create_fixes }}
        GITHUB_REPOSITORY: ${{ github.repository }}

    - name: Gather context data
      shell: bash
      run: |
        chmod +x ${{ github.action_path }}/scripts/preflight.sh
        ${{ github.action_path }}/scripts/preflight.sh
      continue-on-error: true  # Don't fail if context gathering has issues
      env:
        GH_TOKEN: ${{ github.token }}
        GITHUB_WORKFLOW: ${{ github.workflow }}
        GITHUB_REPOSITORY: ${{ github.repository }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        GITHUB_RUN_ATTEMPT: ${{ github.run_attempt }}
        GITHUB_REF: ${{ github.ref }}
        GITHUB_SHA: ${{ github.sha }}
        GITHUB_ACTOR: ${{ github.actor }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}

    - name: Prepare allowed tools
      shell: bash
      run: |
        # Base tools (always available)
        TOOLS="Bash(find . -name \"*.xml\" -o -name \"*.json\" -o -name \"*.log\")
        Bash(gh api repos/${{ github.repository }}/actions/workflows)
        Bash(gh api repos/${{ github.repository }}/issues)
        Bash(gh api repos/${{ github.repository }}/pulls)
        Bash(gh api repos/${{ github.repository }}/commits)
        Bash(cat)
        Bash(grep)
        Bash(jq)
        Bash(date)
        Bash(wc)
        Bash(tail)
        Bash(head)
        Bash(echo)
        Bash(test)"
        
        # Add file editing tools if fixes enabled
        if [ "${{ inputs.create_fixes }}" == "true" ]; then
          TOOLS="$TOOLS
        Edit
        Replace
        CreateFile
        Bash(git)"
        fi
        
        # Add test runners if rerun enabled
        if [ "${{ inputs.rerun_tests }}" == "true" ]; then
          TOOLS="$TOOLS
        Bash(npm)
        Bash(yarn)
        Bash(mvn)
        Bash(gradle)
        Bash(./gradlew)
        Bash(pytest)
        Bash(python)
        Bash(node)
        Bash(java)
        Bash(dotnet)
        Bash(go test)
        Bash(cargo test)
        Bash(php)
        Bash(composer)"
        fi
        
        echo "ALLOWED_TOOLS<<EOF" >> $GITHUB_ENV
        echo "$TOOLS" >> $GITHUB_ENV
        echo "EOF" >> $GITHUB_ENV

    - name: Prepare enhanced prompt
      shell: bash
      run: |
        chmod +x ${{ github.action_path }}/scripts/prepare-prompt.sh
        ${{ github.action_path }}/scripts/prepare-prompt.sh
      continue-on-error: false  # Prompt preparation should not fail
      env:
        CREATE_ISSUES: ${{ inputs.create_issues }}
        CREATE_FIXES: ${{ inputs.create_fixes }}
        RERUN_TESTS: ${{ inputs.rerun_tests }}
        SEVERITY_THRESHOLD: ${{ inputs.severity_threshold }}
        GITHUB_WORKFLOW: ${{ github.workflow }}

    - name: Artemis analyzes the situation
      id: watchdog-analysis
      uses: anthropics/claude-code-base-action@beta
      continue-on-error: true  # Don't let Claude errors break the workflow
      env:
        GH_TOKEN: ${{ github.token }}
      with:
        anthropic_api_key: ${{ inputs.anthropic_api_key }}
        timeout_minutes: 10
        max_turns: 8
        allowed_tools: ${{ env.ALLOWED_TOOLS }}
        prompt_file: .watchdog/claude-prompt.md

    - name: Generate final report
      shell: bash
      run: |
        chmod +x ${{ github.action_path }}/scripts/generate-report.sh
        ${{ github.action_path }}/scripts/generate-report.sh
      continue-on-error: true  # Always try to generate a report, even if incomplete
      env:
        SEVERITY: ${{ steps.watchdog-analysis.outputs.severity }}
        ACTION_TAKEN: ${{ steps.watchdog-analysis.outputs.action_taken }}
        ISSUE_NUMBER: ${{ steps.watchdog-analysis.outputs.issue_number }}
        PR_NUMBER: ${{ steps.watchdog-analysis.outputs.pr_number }}
        TESTS_PASSING: ${{ steps.watchdog-analysis.outputs.tests_passing }}
        INPUT_TOKENS: ${{ steps.watchdog-analysis.outputs.input_tokens }}
        OUTPUT_TOKENS: ${{ steps.watchdog-analysis.outputs.output_tokens }}
        CACHE_READ_TOKENS: ${{ steps.watchdog-analysis.outputs.cache_read_tokens }}
        CACHE_WRITE_TOKENS: ${{ steps.watchdog-analysis.outputs.cache_write_tokens }}
        TOTAL_COST: ${{ steps.watchdog-analysis.outputs.total_cost }}
        TURNS_USED: ${{ steps.watchdog-analysis.outputs.turns_used }}
        CREATE_FIXES: ${{ inputs.create_fixes }}
        RERUN_TESTS: ${{ inputs.rerun_tests }}
        GITHUB_WORKFLOW: ${{ github.workflow }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        GITHUB_SERVER_URL: ${{ github.server_url }}
        GITHUB_REPOSITORY: ${{ github.repository }}

    - name: Upload analysis report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: watchdog-report-${{ github.run_id }}
        path: .watchdog/final-report.md
        retention-days: 30

    - name: Upload debug artifacts
      uses: actions/upload-artifact@v4
      if: always() && inputs.debug_mode == 'true'
      with:
        name: watchdog-debug-${{ github.run_id }}
        path: |
          .watchdog/
          test-results*
          *test*.xml
          *test*.json
          *test*.log
        retention-days: 7

    - name: Extract and ensure outputs are set
      id: ensure-outputs
      shell: bash
      if: always()
      run: |
        echo "üîß Extracting outputs from Claude execution..."
        
        # Initialize default values
        SEVERITY="unknown"
        ACTION_TAKEN="analysis_failed"
        ISSUE_NUMBER=""
        PR_NUMBER=""
        TESTS_PASSING=""
        
        # Check if Claude execution succeeded and extract outputs
        if [ "${{ steps.watchdog-analysis.outputs.conclusion }}" = "success" ] && [ -f "${{ steps.watchdog-analysis.outputs.execution_file }}" ]; then
          echo "üìÑ Parsing Claude execution log..."
          
          # Extract outputs from execution log using jq
          if command -v jq >/dev/null 2>&1; then
            echo "üîç Searching for outputs in execution log..."
            
            # Debug: show what we're working with
            echo "üìÑ Execution file exists: $(ls -la '${{ steps.watchdog-analysis.outputs.execution_file }}' 2>/dev/null || echo 'NOT FOUND')"
            
            # Look for GitHub Action outputs in the execution log - try multiple patterns
            EXEC_FILE="${{ steps.watchdog-analysis.outputs.execution_file }}"
            
            # Method 1: Look for explicit output commands
            SEVERITY=$(grep -o 'severity=[a-z]*' "$EXEC_FILE" 2>/dev/null | tail -1 | cut -d= -f2 || echo "")
            ACTION_TAKEN=$(grep -o 'action_taken=[a-z_]*' "$EXEC_FILE" 2>/dev/null | tail -1 | cut -d= -f2 || echo "")
            ISSUE_NUMBER=$(grep -o 'issue_number=[0-9]*' "$EXEC_FILE" 2>/dev/null | tail -1 | cut -d= -f2 || echo "")
            PR_NUMBER=$(grep -o 'pr_number=[0-9]*' "$EXEC_FILE" 2>/dev/null | tail -1 | cut -d= -f2 || echo "")
            TESTS_PASSING=$(grep -o 'tests_passing=[a-z]*' "$EXEC_FILE" 2>/dev/null | tail -1 | cut -d= -f2 || echo "")
            
            # Method 2: If grep didn't find outputs, try jq parsing
            if [ -z "$SEVERITY" ]; then
              SEVERITY=$(jq -r '.[] | select(.role == "assistant") | .content' "$EXEC_FILE" 2>/dev/null | grep -o 'severity=[a-z]*' | tail -1 | cut -d= -f2 || echo "")
            fi
            
            echo "üîç Found outputs: severity='$SEVERITY', action_taken='$ACTION_TAKEN'"
          fi
          
          # Clean up empty values
          [ "$SEVERITY" = "" ] && SEVERITY="unknown"
          [ "$ACTION_TAKEN" = "" ] && ACTION_TAKEN="none"
        else
          echo "‚ö†Ô∏è Claude analysis failed or no execution file - using fallback values"
        fi
        
        # Set outputs
        echo "severity=$SEVERITY" >> $GITHUB_OUTPUT
        echo "action_taken=$ACTION_TAKEN" >> $GITHUB_OUTPUT
        echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
        echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
        echo "tests_passing=$TESTS_PASSING" >> $GITHUB_OUTPUT
        
        echo "‚úÖ Outputs set: severity=$SEVERITY, action_taken=$ACTION_TAKEN"

branding:
  icon: 'eye'
  color: 'blue'