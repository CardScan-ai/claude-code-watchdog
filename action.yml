name: 'Claude Code Watchdog'
description: 'Your AI watchdog that watches for test failures and heals them automatically'
author: 'CardScan.ai'

inputs:
  anthropic_api_key:
    description: 'Anthropic API key for Claude'
    required: true
  severity_threshold:
    description: 'Minimum severity to process (ignore|low|medium|high|critical)'
    required: false
    default: 'medium'
  create_issues:
    description: 'Create GitHub issues for failures'
    required: false
    default: 'true'
  create_fixes:
    description: 'Attempt to implement fixes automatically'
    required: false
    default: 'true'
  rerun_tests:
    description: 'Attempt to re-run failed tests to confirm fixes'
    required: false
    default: 'false'
  debug_mode:
    description: 'Upload watchdog artifacts for debugging'
    required: false
    default: 'false'
  safe_mode:
    description: 'Skip potentially risky external content (GitHub issues, PRs, commit messages)'
    required: false
    default: 'false'
  test_results_path:
    description: 'Path or glob pattern to test result files (e.g., "test-results/**/*.xml", "cypress/reports/*.json")'
    required: true

outputs:
  severity:
    description: 'Failure severity (ignore|low|medium|high|critical)'
    value: ${{ steps.ensure-outputs.outputs.severity }}
  action_taken:
    description: 'What action was taken (issue_created|issue_updated|pr_created|pr_updated|tests_fixed|none)'
    value: ${{ steps.ensure-outputs.outputs.action_taken }}
  issue_number:
    description: 'GitHub issue number if created or updated'
    value: ${{ steps.ensure-outputs.outputs.issue_number }}
  pr_number:
    description: 'PR number if fixes were created'
    value: ${{ steps.ensure-outputs.outputs.pr_number }}
  tests_passing:
    description: 'true if re-run tests passed after fixes'
    value: ${{ steps.ensure-outputs.outputs.tests_passing }}

runs:
  using: 'composite'
  steps:
    - name: ðŸ• Artemis is on the case
      shell: bash
      run: |
        echo "ðŸ• Woof! Artemis the Watchdog detected test failures..."
        echo "ðŸ” Starting intelligent failure analysis..."

    - name: Validation checks
      shell: bash
      run: |
        node ${{ github.action_path }}/scripts/validate.js
      continue-on-error: false  # Only fail on missing API key
      env:
        GH_TOKEN: ${{ github.token }}
        ANTHROPIC_API_KEY: ${{ inputs.anthropic_api_key }}
        CREATE_FIXES: ${{ inputs.create_fixes }}
        GITHUB_REPOSITORY: ${{ github.repository }}

    - name: Gather context data
      shell: bash
      run: |
        node ${{ github.action_path }}/scripts/preflight.js
      continue-on-error: true  # Don't fail if context gathering has issues
      env:
        GH_TOKEN: ${{ github.token }}
        SAFE_MODE: ${{ inputs.safe_mode }}
        TEST_RESULTS_PATH: ${{ inputs.test_results_path }}
        GITHUB_WORKFLOW: ${{ github.workflow }}
        GITHUB_REPOSITORY: ${{ github.repository }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        GITHUB_RUN_ATTEMPT: ${{ github.run_attempt }}
        GITHUB_REF: ${{ github.ref }}
        GITHUB_SHA: ${{ github.sha }}
        GITHUB_ACTOR: ${{ github.actor }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}

    - name: Prepare allowed tools
      shell: bash
      run: |
        # Base tools for GitHub Actions integration
        TOOLS="Bash,Read,Glob,Grep,LS,Write,Edit"
        
        # Add additional file editing tools if fixes enabled
        if [ "${{ inputs.create_fixes }}" == "true" ]; then
          TOOLS="$TOOLS,MultiEdit"
        fi
        
        echo "ALLOWED_TOOLS=$TOOLS" >> $GITHUB_ENV

    - name: Load system prompt
      id: load-system-prompt
      shell: bash
      run: |
        # Use printf to properly handle multiline content
        {
          echo "system_prompt<<PROMPT_EOF_DELIMITER"
          cat "${{ github.action_path }}/scripts/system-prompt.md"
          echo ""
          echo "PROMPT_EOF_DELIMITER"
        } >> "$GITHUB_OUTPUT"

    - name: Prepare enhanced prompt
      shell: bash
      run: |
        node ${{ github.action_path }}/scripts/prepare-prompt.js
      continue-on-error: false  # Prompt preparation should not fail
      env:
        CREATE_ISSUES: ${{ inputs.create_issues }}
        CREATE_FIXES: ${{ inputs.create_fixes }}
        RERUN_TESTS: ${{ inputs.rerun_tests }}
        SEVERITY_THRESHOLD: ${{ inputs.severity_threshold }}
        SAFE_MODE: ${{ inputs.safe_mode }}
        GITHUB_WORKFLOW: ${{ github.workflow }}

    - name: Artemis analyzes the situation
      id: watchdog
      uses: anthropics/claude-code-base-action@beta
      continue-on-error: true  # Don't let Claude errors break the workflow
      env:
        GH_TOKEN: ${{ github.token }}
      with:
        anthropic_api_key: ${{ inputs.anthropic_api_key }}
        timeout_minutes: 10
        max_turns: 8
        allowed_tools: ${{ env.ALLOWED_TOOLS }}
        system_prompt: ${{ steps.load-system-prompt.outputs.system_prompt }}
        prompt_file: .watchdog/context-data.md

    - name: Generate final report
      shell: bash
      run: |
        node ${{ github.action_path }}/scripts/generate-report.js
      continue-on-error: true  # Always try to generate a report, even if incomplete
      env:
        SEVERITY: ${{ steps.watchdog.outputs.severity }}
        ACTION_TAKEN: ${{ steps.watchdog.outputs.action_taken }}
        ISSUE_NUMBER: ${{ steps.watchdog.outputs.issue_number }}
        PR_NUMBER: ${{ steps.watchdog.outputs.pr_number }}
        TESTS_PASSING: ${{ steps.watchdog.outputs.tests_passing }}
        INPUT_TOKENS: ${{ steps.watchdog.outputs.input_tokens }}
        OUTPUT_TOKENS: ${{ steps.watchdog.outputs.output_tokens }}
        CACHE_READ_TOKENS: ${{ steps.watchdog.outputs.cache_read_tokens }}
        CACHE_WRITE_TOKENS: ${{ steps.watchdog.outputs.cache_write_tokens }}
        TOTAL_COST: ${{ steps.watchdog.outputs.total_cost }}
        TURNS_USED: ${{ steps.watchdog.outputs.turns_used }}
        CREATE_FIXES: ${{ inputs.create_fixes }}
        RERUN_TESTS: ${{ inputs.rerun_tests }}
        GITHUB_WORKFLOW: ${{ github.workflow }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        GITHUB_SERVER_URL: ${{ github.server_url }}
        GITHUB_REPOSITORY: ${{ github.repository }}

    - name: Upload analysis report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: watchdog-report-${{ github.run_id }}
        path: .watchdog/final-report.md
        retention-days: 30


    - name: Create debug archive
      if: always() && inputs.debug_mode == 'true'
      shell: bash
      run: |
        # Create minimal debug archive with key files
        if [ -d .watchdog ] && [ "$(find .watchdog -type f 2>/dev/null | wc -l)" -gt 0 ]; then
          tar -czf watchdog-debug.tar.gz .watchdog/
        else
          echo "No watchdog files generated" > watchdog-debug-empty.txt
        fi

    - name: Upload debug artifacts
      uses: actions/upload-artifact@v4
      if: always() && inputs.debug_mode == 'true'
      with:
        name: watchdog-debug-${{ github.run_id }}
        path: |
          watchdog-debug.tar.gz
          watchdog-debug-empty.txt
        retention-days: 7
        if-no-files-found: warn

    - name: Extract and ensure outputs are set
      id: ensure-outputs
      shell: bash
      if: always()
      run: |
        node ${{ github.action_path }}/scripts/extract-outputs.js
      env:
        CLAUDE_CONCLUSION: ${{ steps.watchdog.outputs.conclusion }}
        CLAUDE_EXECUTION_FILE: ${{ steps.watchdog.outputs.execution_file }}

branding:
  icon: 'eye'
  color: 'blue'